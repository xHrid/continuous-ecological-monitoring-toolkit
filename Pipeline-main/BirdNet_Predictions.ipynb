{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import spectrogram\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\20072025-29072025_2R4W\\results.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_2_peacock_spot\\20072025-03082025_2R4W\\results.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_4_yoga_spot\\20072025-03082025_2R4W\\results.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_3_investigation_spot\\20072025-03082025_2R4W\\results.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT SURE IF NEEDED ANYMORE, now that we use a library directly\n",
    "# -------------------- Load GPU Delegate --------------------\n",
    "delegate = None\n",
    "try:\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "except ModuleNotFoundError:\n",
    "    from tensorflow import lite as tflite\n",
    "\n",
    "try:\n",
    "    delegate = tf.lite.experimental.load_delegate(\"libtensorflowlite_gpu_delegate.so\")\n",
    "    print(\"GPU delegate loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"GPU delegate not available:\", e)\n",
    "\n",
    "# -------------------- Patch Interpreter BEFORE importing wrapper --------------------\n",
    "if not hasattr(tflite, \"_original_interpreter\"):\n",
    "    tflite._original_interpreter = tflite.Interpreter\n",
    "\n",
    "    def Interpreter_with_delegate(*args, **kwargs):\n",
    "        if delegate is not None:\n",
    "            kwargs[\"experimental_delegates\"] = [delegate]\n",
    "        return tflite._original_interpreter(*args, **kwargs)\n",
    "\n",
    "    tflite.Interpreter = Interpreter_with_delegate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "# -------------------- Step 1: Data Consolidation --------------------\n",
    "all_data = []\n",
    "for i, file_path in enumerate(results_combined):\n",
    "    df_spot = pd.read_csv(file_path)\n",
    "    # Add a 'Spot' column to identify the source of the data\n",
    "    df_spot['Spot'] = f'Spot {i+1}'\n",
    "    all_data.append(df_spot)\n",
    "\n",
    "# Concatenate all DataFrames into a single master DataFrame\n",
    "master_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# -------------------- Step 2: Segment Mapping --------------------\n",
    "def map_to_segment(hour):\n",
    "    if 21 <= hour or hour < 5:\n",
    "        return 'Night'\n",
    "    elif 5 <= hour < 10:\n",
    "        return 'Morning'\n",
    "    elif 10 <= hour < 17:\n",
    "        return 'Day'\n",
    "    else:  # 17 to 21\n",
    "        return 'Evening'\n",
    "\n",
    "master_df['Segment'] = master_df['Hour'].apply(map_to_segment)\n",
    "\n",
    "# -------------------- Step 3: Aggregation for PCA --------------------\n",
    "acoustic_indices = ['ADI', 'ACI', 'AEI', 'NDSI', 'CLS']\n",
    "\n",
    "df_pca = master_df.groupby(['Spot', 'Segment'])[acoustic_indices].mean().reset_index()\n",
    "\n",
    "print(\"Aggregated Data for PCA:\")\n",
    "print(df_pca)\n",
    "print(\"\\n\")\n",
    "\n",
    "# -------------------- Step 4: Scaling and PCA --------------------\n",
    "features = df_pca[acoustic_indices]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# -------------------- Step 5: Combining and Visualization --------------------\n",
    "final_pca_df = pd.concat([df_pca[['Spot', 'Segment']], pca_df], axis=1)\n",
    "\n",
    "print(\"Final PCA Results:\")\n",
    "print(final_pca_df)\n",
    "\n",
    "# Visualization of PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=final_pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    hue='Spot',        # Color points by Spot\n",
    "    style='Segment',   # Differentiate markers by Time Segment\n",
    "    s=150,             # Set marker size\n",
    "    palette='viridis'  # Choose a color palette\n",
    ")\n",
    "\n",
    "plt.title('PCA of Acoustic Indices by Spot and Time Segment')\n",
    "plt.xlabel('Principal Component 1 (PC1)')\n",
    "plt.ylabel('Principal Component 2 (PC2)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Explained variance plot to choose number of components\n",
    "pca_full = PCA()\n",
    "pca_full.fit(scaled_features)\n",
    "explained_variance = pca_full.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.cumsum(explained_variance), marker='o', linestyle='--')\n",
    "plt.title('Explained Variance vs. Number of Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.axhline(y=0.95, color='r', linestyle='-', label='95% Cutoff')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Step 1: Data Consolidation --------------------\n",
    "all_data = []\n",
    "for i, file_path in enumerate(results_combined):\n",
    "    df_spot = pd.read_csv(file_path)\n",
    "    # Add a 'Spot' column to identify the source of the data\n",
    "    df_spot['Spot'] = f'Spot {i+1}'\n",
    "    all_data.append(df_spot)\n",
    "\n",
    "master_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# -------------------- Step 2: Segment Mapping --------------------\n",
    "def map_to_segment(hour):\n",
    "    if 21 <= hour or hour < 5:\n",
    "        return 'Night'\n",
    "    elif 5 <= hour < 10:\n",
    "        return 'Morning'\n",
    "    elif 10 <= hour < 17:\n",
    "        return 'Day'\n",
    "    else:  # 17 to 21\n",
    "        return 'Evening'\n",
    "\n",
    "master_df['Segment'] = master_df['Hour'].apply(map_to_segment)\n",
    "\n",
    "# -------------------- Step 3: Aggregation for PCA --------------------\n",
    "acoustic_indices = ['ADI', 'ACI', 'AEI', 'NDSI', 'CLS']\n",
    "df_pca = master_df.groupby(['Spot', 'Segment'])[acoustic_indices].mean().reset_index()\n",
    "\n",
    "# -------------------- Step 4: Scaling and PCA --------------------\n",
    "features = df_pca[acoustic_indices]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "final_pca_df = pd.concat([df_pca[['Spot', 'Segment']], pca_df], axis=1)\n",
    "\n",
    "\n",
    "# -------------------- Step 5: Create the PCA Matrix Grid --------------------\n",
    "# Create two pivot tables, one for PC1 and one for PC2\n",
    "pc1_grid = final_pca_df.pivot(index='Segment', columns='Spot', values='PC1')\n",
    "pc2_grid = final_pca_df.pivot(index='Segment', columns='Spot', values='PC2')\n",
    "\n",
    "# Reorder the index to match the time segments\n",
    "segment_order = ['Night', 'Morning', 'Day', 'Evening']\n",
    "pc1_grid = pc1_grid.reindex(segment_order)\n",
    "pc2_grid = pc2_grid.reindex(segment_order)\n",
    "\n",
    "# -------------------- Step 6: Visualize the Matrix Grids --------------------\n",
    "\n",
    "# --- Heatmap for PC1 ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    pc1_grid,\n",
    "    annot=True,          # Show the numerical values\n",
    "    fmt=\".2f\",           # Format to two decimal places\n",
    "    cmap=\"coolwarm\",     # Use a diverging color palette\n",
    "    center=0,            # Center the color scale at 0\n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Aggregated Acoustic Profile (PC1 Score)'}\n",
    ")\n",
    "plt.title('PC1 Score Matrix Grid by Spot and Time Segment')\n",
    "plt.xlabel('Monitoring Spot')\n",
    "plt.ylabel('Time Segment')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Heatmap for PC2 ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    pc2_grid,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Aggregated Acoustic Profile (PC2 Score)'}\n",
    ")\n",
    "plt.title('PC2 Score Matrix Grid by Spot and Time Segment')\n",
    "plt.xlabel('Monitoring Spot')\n",
    "plt.ylabel('Time Segment')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Boxplot Visualization --------------------\n",
    "# Create boxplots for each index (Confidence, ADI, ACI, AEI, NDSI) by Hour.\n",
    "\n",
    "for i in range(len(results_combined)):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pd.read_csv(results_combined[i]).boxplot(column=\"CLS\", by=\"Hour\", grid=True)\n",
    "    plt.title(f\"CLS per Hour (Boxplot) Spot {i+1}\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Hour\")\n",
    "    plt.ylabel(\"CLS\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"boxplot _per_hour.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Generation of BirdNet predictions\n",
    "\n",
    "- **Generating Lat-Long specific species list**\n",
    "- **Predictions** Gives one bird for one 3 second segment if detected (also no bird for some segments) with a confidence score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"E:\\archive\\BirdNET-Analyzer\\analyze.py\" --i \"E:\\Sanjay_Van_Monitoring\\Origin Spot\\02062025-13062025_30R30W\\recordings\\04213SPOT1_20250602_120000.wav\" --o \"E:\\Sanjay_Van_Monitoring\\Origin Spot\\02062025-13062025_30R30W\\BirdNET_Temp_Results\" --lat 28.53 --lon 77.18 --week 24 --min_conf 0.5 --rtype csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio, sr = librosa.load(r\"E:\\Sanjay_Van_Monitoring\\Origin Spot\\02062025-13062025_30R30W\\recordings\\04213SPOT1_20250602_120000.wav\", sr=None)\n",
    "print(f\"Loaded successfully with sample rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python E:\\archive\\BirdNET-Analyzer\\species.py --lat 28.53 --lon 77.18 --week 24 --sf_thresh 0.1 \"E:\\species_list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "script_path = r\"E:\\archive\\BirdNET-Analyzer\\species.py\"\n",
    "\n",
    "output_file = r\"E:\\species_list.txt\"\n",
    "\n",
    "# Set the location, week, and threshold\n",
    "lat = \"28.53\"\n",
    "lon = \"77.18\"\n",
    "week = \"24\"\n",
    "threshold = \"0.05\"\n",
    "\n",
    "command = [\n",
    "    sys.executable, script_path,\n",
    "    \"--lat\", lat,\n",
    "    \"--lon\", lon,\n",
    "    \"--week\", week,\n",
    "    \"--threshold\", threshold,\n",
    "    \"--o\", output_file\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "try:\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"✅ Species list written to: {output_file}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"❌ Failed to generate species list:\")\n",
    "    print(e.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install birdnetlib --trusted-host pypi.org --trusted-host files.pythonhosted.org\n",
    "!pip install resampy --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "np.complex = complex  # Monkey patch for compatibility\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "TARGET_SR = 48000\n",
    "SNR_DB = 18\n",
    "\n",
    "# ==================== DENOISING FUNCTION ====================\n",
    "def remove_static_noise(audio, noise_ref, sr=TARGET_SR, snr_db=SNR_DB):\n",
    "    if len(noise_ref) > len(audio):\n",
    "        noise_ref = noise_ref[:len(audio)]\n",
    "    else:\n",
    "        noise_ref = np.pad(noise_ref, (0, len(audio) - len(noise_ref)), 'wrap')\n",
    "    audio_power = np.mean(audio ** 2)\n",
    "    noise_power = np.mean(noise_ref ** 2)\n",
    "    desired_noise_power = audio_power / (10 ** (snr_db / 10))\n",
    "    noise_ref_scaled = noise_ref * np.sqrt(desired_noise_power / noise_power)\n",
    "    audio_td = audio - noise_ref_scaled\n",
    "    stft = librosa.stft(audio_td, n_fft=2048, hop_length=512)\n",
    "    magnitude, phase = np.abs(stft), np.angle(stft)\n",
    "    noise_stft = librosa.stft(noise_ref, n_fft=2048, hop_length=512)\n",
    "    noise_mag = np.abs(noise_stft)\n",
    "    noise_threshold = np.mean(noise_mag, axis=1, keepdims=True) * 1.2\n",
    "    gated_mag = np.where(magnitude > noise_threshold, magnitude, 0)\n",
    "    cleaned_stft = gated_mag * np.exp(1j * phase)\n",
    "    return librosa.istft(cleaned_stft, hop_length=512)\n",
    "\n",
    "# ==================== LOAD STATIC NOISE CLIP ====================\n",
    "STATIC_NOISE_PATH = r\"E:\\projects\\acoustic_biodiversity\\static_noise.wav\"\n",
    "noise_clip, _ = librosa.load(STATIC_NOISE_PATH, sr=TARGET_SR)\n",
    "\n",
    "import tempfile\n",
    "def analyze_bird_audio(audio_path, lat, lon):\n",
    "    # Step 1: Load audio with original sampling rate\n",
    "    audio_raw, orig_sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # Step 2: Resample if needed\n",
    "    if orig_sr != TARGET_SR:\n",
    "        audio_raw = librosa.resample(y=audio_raw, orig_sr=orig_sr, target_sr=TARGET_SR)\n",
    "\n",
    "    \n",
    "    # Step 3: Denoise\n",
    "    final_sound = remove_static_noise(audio_raw, noise_clip, sr=TARGET_SR, snr_db=SNR_DB)\n",
    "\n",
    "    # Step 4: Save to temp WAV file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpfile:\n",
    "        sf.write(tmpfile.name, final_sound, samplerate=TARGET_SR)\n",
    "        tmp_audio_path = tmpfile.name\n",
    "\n",
    "    # Step 5: Analyze with BirdNET\n",
    "    analyzer = Analyzer()\n",
    "    recording = Recording(\n",
    "        analyzer,\n",
    "        tmp_audio_path,\n",
    "        lat=lat,\n",
    "        lon=lon,\n",
    "        #date=date,\n",
    "        #min_conf=min_conf,\n",
    "    )\n",
    "    recording.analyze()\n",
    "    \n",
    "    return pd.DataFrame(recording.detections)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df = analyze_bird_audio(\n",
    "    audio_path=r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\21062025-05072025_5R5W\\recordings\\04213SPOT1_20250621_081000.wav\",\n",
    "    lat=28.53,\n",
    "    lon=77.18,\n",
    "    # date=\"2024-06-12\",\n",
    "    #min_conf=0.3\n",
    ")\n",
    "\n",
    "print(detections_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\20072025-29072025_2R4W\\recordings\", r\"E:\\monitoring_data\\sound_recordings\\spot_2_peacock_spot\\20072025-03082025_2R4W\\recordings\", r\"E:\\monitoring_data\\sound_recordings\\spot_4_yoga_spot\\20072025-03082025_2R4W\\recordings\", r\"E:\\monitoring_data\\sound_recordings\\spot_3_investigation_spot\\20072025-03082025_2R4W\\recordings\"]\n",
    "OUTPUTS = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\20072025-29072025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_2_peacock_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_4_yoga_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_3_investigation_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE FINAL PREDICTIONS FUNCTION\n",
    "# IT GIVES A REALLY HUGE CELL OUTPUT SO THAT NEEDS TO BE CHANGED TO ONE LIKE PER FILE HOPEFULLY\n",
    "\n",
    "# Your function to extract datetime components\n",
    "def extract_year_month_date_hour_and_minute(filename):\n",
    "    match_date = re.search(r'_(\\d{8})_', filename)\n",
    "    match = re.search(r'_(\\d{6})\\.wav$', filename)\n",
    "    if match and match_date:\n",
    "        time_str = match.group(1)\n",
    "        date_str = match_date.group(1)\n",
    "        year = date_str[:4]\n",
    "        month = date_str[4:6]\n",
    "        day = date_str[6:]\n",
    "        hour = int(time_str[:2])\n",
    "        minute = int(time_str[2:4])\n",
    "        return year, month, day, hour, minute\n",
    "    return None, None, None, None, None\n",
    "\n",
    "# Directory containing WAV recordings\n",
    "\n",
    "for i in range(4):\n",
    "    # Store all detections\n",
    "    all_detections = []\n",
    "\n",
    "    # Loop through all .wav files\n",
    "    for fname in os.listdir(DATASETS[i]):\n",
    "        if fname.lower().endswith(\".wav\"):\n",
    "            filepath = os.path.join(DATASETS[i], fname)\n",
    "\n",
    "            # Extract date from filename (required by BirdNET)\n",
    "            year, month, day, hour, minute = extract_year_month_date_hour_and_minute(fname)\n",
    "            if None in [year, month, day]:\n",
    "                print(f\"Skipping file due to unmatched filename format: {fname}\")\n",
    "                continue\n",
    "\n",
    "            # Format as YYYY-MM-DD\n",
    "            date_str = f\"{year}-{month}-{day}\"\n",
    "\n",
    "            try:\n",
    "                # Run BirdNET analysis\n",
    "                detections_df = analyze_bird_audio(\n",
    "                    audio_path=filepath,\n",
    "                    lat=28.53,\n",
    "                    lon=77.18\n",
    "                    # date=date_str,\n",
    "                    # min_conf=0.3\n",
    "                )\n",
    "\n",
    "                # Add filename and datetime columns\n",
    "                detections_df[\"filename\"] = fname\n",
    "                detections_df[\"year\"] = year\n",
    "                detections_df[\"month\"] = month\n",
    "                detections_df[\"day\"] = day\n",
    "                detections_df[\"hour\"] = hour\n",
    "                detections_df[\"minute\"] = minute\n",
    "\n",
    "                all_detections.append(detections_df)\n",
    "\n",
    "                # ✅ Print progress\n",
    "                print(f\"Processed file: {fname} with {len(detections_df)} detections.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "    # Combine all detections\n",
    "    if all_detections:\n",
    "        final_df = pd.concat(all_detections, ignore_index=True)\n",
    "        final_df.to_csv(OUTPUTS[i], index=False)\n",
    "        print(\"Saved detections to 'birdnet_detections_all.csv'\")\n",
    "    else:\n",
    "        print(\"No detections processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATASETS = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\20072025-29072025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_2_peacock_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_4_yoga_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_3_investigation_spot\\20072025-03082025_2R4W\\birdnet_classification.csv\"]\n",
    "\n",
    "\n",
    "dataset_list = [pd.read_csv(file) for file in DATASETS]\n",
    "data = pd.concat(dataset_list, ignore_index=True)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique common names\n",
    "unique_names = data[\"label\"].dropna().unique()\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"unique_common_names.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for name in unique_names:\n",
    "        f.write(name + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7: Validation of Output \n",
    "\n",
    "- **Confusion Matrix** This gives all the values needed for the confusion matrix\n",
    "- The latest species list is generated from unique bird names from combined_df in graph_spot3_4\n",
    "- The 222 validation bird list has been created from eBird and is considered as ground truth since it is the same list on Myna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- DATA INPUT ---\n",
    "# The raw text data variables will be placed here.\n",
    "# I'm omitting them for brevity in this response, but they are the same as before.\n",
    "\n",
    "ebird_raw_text = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "birdnet_spot1_raw = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# --- DATA PROCESSING FUNCTIONS (Unchanged) ---\n",
    "def parse_ebird_list(raw_text):\n",
    "    species_set = set()\n",
    "    pattern = re.compile(r\"^(.*?)\\s+[A-Z][a-z]+ [a-z]+\")\n",
    "    for line in raw_text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            common_name = match.group(1).strip()\n",
    "            # Standardize a name for better matching\n",
    "            if \"Honey Buzzard\" in common_name:\n",
    "                common_name = \"Oriental Honey-buzzard\"\n",
    "            species_set.add(common_name)\n",
    "    return species_set\n",
    "\n",
    "def parse_birdnet_list(raw_text):\n",
    "    species_set = set()\n",
    "    non_bird_sounds = {\n",
    "        'Engine', 'Siren', 'Fireworks', 'Gun', 'Human vocal', 'Gray Wolf',\n",
    "        'Southeastern Field Cricket', 'Jumping Bush Cricket', 'Carolina Ground Cricket',\n",
    "        'Green Treefrog', 'American Bullfrog', 'Adelie Penguin', 'King Penguin'\n",
    "    }\n",
    "    for line in raw_text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line or '_' not in line or 'Spot' in line: continue\n",
    "        parts = line.split('_', 1)\n",
    "        if len(parts) < 2: continue\n",
    "        common_name = parts[1].replace('-', ' ').strip()\n",
    "        is_junk = any(junk in common_name for junk in non_bird_sounds)\n",
    "        if not is_junk:\n",
    "            species_set.add(common_name)\n",
    "    return species_set\n",
    "\n",
    "def check_plausibility(species_list):\n",
    "    implausible_keywords = [\n",
    "        # Continents/Regions\n",
    "        'American', 'African', 'Andean', 'Puerto Rican', 'Madagascar', 'Palau', 'Yungas',\n",
    "        # North/Central America\n",
    "        'Canada', 'Canadian', 'Carolina', 'Kentucky', 'Louisiana', 'Mississippi', 'Acadian',\n",
    "        'MacGillivray', 'Red cockaded', 'Pileated', 'Gila', 'Red bellied', 'Hairy',\n",
    "        'Cuban', 'Yucatan', 'Bahama', 'Cave Swallow', 'Sinaloa', 'Mexican', 'Steller', 'Bald Eagle',\n",
    "        # South America\n",
    "        'Peruvian', 'Bamboo Antshrike', 'Acre Tody Tyrant', 'Hoatzin',\n",
    "        # Australia/Pacific\n",
    "        'Pacific', 'Mauritius', 'Ryukyu', 'Akiapolaau', 'Akohekohe',\n",
    "        'Wonga Pigeon', 'Noisy Miner', 'Pied Currawong', 'Crescent Honeyeater',\n",
    "        # Marine/Antarctic\n",
    "        'Penguin', 'Kittiwake', 'Manx Shearwater', 'Auklet', 'Loon',\n",
    "        # Specific out-of-place species\n",
    "        'Veery', 'Wonga Pigeon'\n",
    "    ]\n",
    "    plausible, implausible = [], []\n",
    "    for species in sorted(list(species_list)):\n",
    "        is_implausible = any(keyword in species for keyword in implausible_keywords)\n",
    "        if is_implausible:\n",
    "            implausible.append(species)\n",
    "        else:\n",
    "            plausible.append(species)\n",
    "    return plausible, implausible\n",
    "\n",
    "def print_list(title, item_list, indent=\"\"):\n",
    "    print(f\"{indent}--- {title} ({len(item_list)}) ---\")\n",
    "    if not item_list:\n",
    "        print(f\"{indent}None\")\n",
    "        return\n",
    "    for item in sorted(item_list):\n",
    "        print(f\"{indent}- {item}\")\n",
    "\n",
    "# --- ANALYSIS EXECUTION (CORRECTED LOGIC) ---\n",
    "\n",
    "# 1. Parse all data\n",
    "ebird_species = parse_ebird_list(ebird_raw_text)\n",
    "birdnet_spot1 = parse_birdnet_list(birdnet_spot1_raw)\n",
    "\n",
    "\n",
    "# 2. Create the UNION of all BirdNET detections\n",
    "birdnet_total_union = birdnet_spot1 \n",
    "\n",
    "# 3. Compare the complete eBird list vs the complete BirdNET list\n",
    "confirmed_by_birdnet = ebird_species & birdnet_total_union\n",
    "missed_by_birdnet = ebird_species - birdnet_total_union\n",
    "birdnet_only_detections = birdnet_total_union - ebird_species\n",
    "\n",
    "# 4. Categorize the BirdNET-only detections\n",
    "plausible_birdnet_only, implausible_birdnet_only = check_plausibility(birdnet_only_detections)\n",
    "\n",
    "# 5. For deeper analysis, find where the plausible detections occurred\n",
    "#    FIX: Convert the list 'plausible_birdnet_only' to a set for intersection operations\n",
    "plausible_set = set(plausible_birdnet_only)\n",
    "\n",
    "\n",
    "# --- REVISED REPORTING ---\n",
    "\n",
    "print(\"############################################################\")\n",
    "print(\"###      Sanjayvan Bird Data Analysis (Site-Level)       ###\")\n",
    "print(\"############################################################\")\n",
    "\n",
    "print(\"\\n================== OVERALL SUMMARY ===================\")\n",
    "print(f\"eBird Species List (Ground Truth): {len(ebird_species)}\")\n",
    "print(f\"Total Unique Bird Detections by BirdNET (across both spots): {len(birdnet_total_union)}\")\n",
    "\n",
    "print(\"\\n\\n=============== PART 1: CONFIRMED SPECIES ===============\")\n",
    "print(\"This section compares the eBird list to the total BirdNET detections.\")\n",
    "print_list(\"Species on eBird List CONFIRMED by BirdNET (at one or both spots)\", confirmed_by_birdnet)\n",
    "print_list(\"Species on eBird List MISSED by BirdNET (Acoustic Blind Spots)\", missed_by_birdnet)\n",
    "\n",
    "\n",
    "print(\"\\n\\n========= PART 2: THE INVESTIGATION LIST (PLAUSIBLE but UNCONFIRMED) =========\")\n",
    "print(\"This is the PRIMARY list for manual review. These are species that are geographically\")\n",
    "print(\"plausible but not on the official eBird list for Sanjayvan.\")\n",
    "print_list(\"TOTAL Plausible but Unconfirmed Species found across both spots\", plausible_birdnet_only)\n",
    "\n",
    "\n",
    "print(\"\\n\\n=============== PART 3: THE JUNK PILE (IMPLAUSIBLE DETECTIONS) ===============\")\n",
    "print(\"These are clear system errors where BirdNET misidentified sounds as birds from\")\n",
    "print(\"other continents or environments. They should be disregarded.\")\n",
    "print_list(\"TOTAL Geographically IMPLAUSIBLE species detected\", implausible_birdnet_only)\n",
    "\n",
    "print(\"\\n############################################################\")\n",
    "print(\"###                 Analysis Conclusion                  ###\")\n",
    "print(\"############################################################\")\n",
    "print(f\"\"\"\n",
    "This revised analysis takes a site-level approach, providing a clearer picture for Sanjayvan as a whole.\n",
    "\n",
    "1.  **System Performance:** BirdNET successfully confirmed the presence of **{len(confirmed_by_birdnet)}** species from the official {len(ebird_species)}-species eBird list. However, it completely missed **{len(missed_by_birdnet)}** known species, highlighting its limitations with non-vocal or quiet birds.\n",
    "\n",
    "2.  **The Actionable 'Investigation List':** The most critical output is the single, unified list of **{len(plausible_birdnet_only)} plausible but unconfirmed species**. This list, created by taking the **union** of all plausible detections from both spots, represents every potential new sighting or misidentification that warrants expert review.\n",
    "    - To help prioritize this list, of these species were detected at *both* spots. These should be investigated first, as multiple detections could indicate a higher (though still low) chance of being a genuine, repeated call.\n",
    "\n",
    "3.  **Quantifying System Error:** The analysis identified a Junk Pile of **{len(implausible_birdnet_only)} geographically impossible species**. The presence of birds like the 'Red-shouldered Hawk' (North America) and 'Congo Serpent Eagle' (Africa) is definitive proof of the system's high error rate. This number serves as a crucial reminder to treat all unconfirmed BirdNET detections with extreme skepticism.\n",
    "\n",
    "**Final Recommendation:**\n",
    "The workflow for a researcher or manager should be:\n",
    "1.  **Trust the eBird list** as the verified baseline.\n",
    "2.  **Use the 'Investigation List' ({len(plausible_birdnet_only)} species) as your to-do list.** Go back to the source audio files for each of these detections and have an expert ornithologist listen to them to determine if they are genuine vagrants or misidentifications of common local species.\n",
    "3.  **Completely disregard the 'Junk Pile'** of {len(implausible_birdnet_only)} species as known system errors.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
