{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Calculation of Indices\n",
    "\n",
    "- Calculates and saves indices into a csv after preprocessing sound data\n",
    "- Indices Computed: ADI, ACI, AEI, NDSI, CLS, MFC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T13:57:03.555115Z",
     "iopub.status.busy": "2025-06-19T13:57:03.553994Z",
     "iopub.status.idle": "2025-06-19T13:57:03.560944Z",
     "shell.execute_reply": "2025-06-19T13:57:03.559766Z",
     "shell.execute_reply.started": "2025-06-19T13:57:03.555075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.signal import spectrogram, find_peaks\n",
    "from scipy.stats import entropy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T13:57:05.843235Z",
     "iopub.status.busy": "2025-06-19T13:57:05.842844Z",
     "iopub.status.idle": "2025-06-19T13:57:05.854239Z",
     "shell.execute_reply": "2025-06-19T13:57:05.853308Z",
     "shell.execute_reply.started": "2025-06-19T13:57:05.843182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------- Load GPU Delegate --------------------\n",
    "delegate = None\n",
    "try:\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "except ModuleNotFoundError:\n",
    "    from tensorflow import lite as tflite\n",
    "\n",
    "try:\n",
    "    delegate = tf.lite.experimental.load_delegate(\"libtensorflowlite_gpu_delegate.so\")\n",
    "    print(\"GPU delegate loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"GPU delegate not available:\", e)\n",
    "\n",
    "# -------------------- Patch Interpreter BEFORE importing wrapper --------------------\n",
    "if not hasattr(tflite, \"_original_interpreter\"):\n",
    "    tflite._original_interpreter = tflite.Interpreter\n",
    "\n",
    "    def Interpreter_with_delegate(*args, **kwargs):\n",
    "        if delegate is not None:\n",
    "            kwargs[\"experimental_delegates\"] = [delegate]\n",
    "        return tflite._original_interpreter(*args, **kwargs)\n",
    "\n",
    "    tflite.Interpreter = Interpreter_with_delegate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T13:57:12.707142Z",
     "iopub.status.busy": "2025-06-19T13:57:12.706754Z",
     "iopub.status.idle": "2025-06-19T13:57:12.712437Z",
     "shell.execute_reply": "2025-06-19T13:57:12.711272Z",
     "shell.execute_reply.started": "2025-06-19T13:57:12.707109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\21062025-05072025_5R5W\\recordings\", r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\08072025-11072025_2R4W\\recordings\"]\n",
    "STATIC_NOISE_PATH = r\"E:\\projects\\acoustic_biodiversity\\static_noise.wav\"\n",
    "TARGET_SR = 48000\n",
    "OUTPUT_CSV = [r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\21062025-05072025_5R5W\\results.csv\", r\"E:\\monitoring_data\\sound_recordings\\spot_1_original_spot\\08072025-11072025_2R4W\\results.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T13:57:25.487484Z",
     "iopub.status.busy": "2025-06-19T13:57:25.487071Z",
     "iopub.status.idle": "2025-06-19T13:57:25.504648Z",
     "shell.execute_reply": "2025-06-19T13:57:25.503283Z",
     "shell.execute_reply.started": "2025-06-19T13:57:25.487459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_year_month_date_hour_and_minute(filename):\n",
    "    \"\"\"Extracts hour and minute from filenames like '2MM07103_20250330_143000.wav'.\"\"\"\n",
    "    match_date = re.search(r'_(\\d{8})_', filename)\n",
    "    match = re.search(r'_(\\d{6})\\.wav$', filename)\n",
    "    if match and match_date:\n",
    "        time_str = match.group(1)\n",
    "        date_str = match_date.group(1)\n",
    "        year = date_str[:4]\n",
    "        month = date_str[4:6]\n",
    "        date = date_str[6:]\n",
    "        hour = int(time_str[:2])\n",
    "        minute = int(time_str[2:4])\n",
    "        return year, month, date, hour, minute\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def remove_static_noise(audio, noise_ref, sr=TARGET_SR, snr_db=18):\n",
    "    \"\"\"\n",
    "    Combines time-domain noise subtraction and spectral gating to remove static noise.\n",
    "    \n",
    "    1. Time-Domain Subtraction:  \n",
    "       - The noise reference is padded (using 'wrap' mode) to match the audio length.\n",
    "       - Its power is scaled (using the desired SNR) and subtracted from the audio.\n",
    "       \n",
    "    2. Spectral Gating:  \n",
    "       - The resulting audio is transformed into the frequency domain using STFT.\n",
    "       - A noise threshold is computed from the noise reference (via its STFT).\n",
    "       - Frequency bins with energy below the threshold are zeroed out.\n",
    "       - The audio is reconstructed using the inverse STFT.\n",
    "    \"\"\"\n",
    "    # --- Time-Domain Subtraction ---\n",
    "    if len(noise_ref) > len(audio):\n",
    "        noise_ref = noise_ref[:len(audio)]\n",
    "    else:\n",
    "        noise_ref = np.pad(noise_ref, (0, len(audio) - len(noise_ref)), 'wrap')\n",
    "    \n",
    "    audio_power = np.mean(audio ** 2)\n",
    "    noise_power = np.mean(noise_ref ** 2)\n",
    "    desired_noise_power = audio_power / (10 ** (snr_db / 10))\n",
    "    noise_ref_scaled = noise_ref * np.sqrt(desired_noise_power / noise_power)\n",
    "    audio_td = audio - noise_ref_scaled\n",
    "\n",
    "    # --- Spectral Gating ---\n",
    "    stft = librosa.stft(audio_td, n_fft=2048, hop_length=512)\n",
    "    magnitude, phase = np.abs(stft), np.angle(stft)\n",
    "\n",
    "    noise_stft = librosa.stft(noise_ref, n_fft=2048, hop_length=512)\n",
    "    noise_mag = np.abs(noise_stft)\n",
    "    noise_threshold = np.mean(noise_mag, axis=1, keepdims=True) * 1.2  # threshold factor\n",
    "\n",
    "    gated_mag = np.where(magnitude > noise_threshold, magnitude, 0)\n",
    "    cleaned_stft = gated_mag * np.exp(1j * phase)\n",
    "    audio_cleaned = librosa.istft(cleaned_stft, hop_length=512)\n",
    "\n",
    "    return audio_cleaned\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa  # For loading audio files\n",
    "import os\n",
    "from scipy.signal import spectrogram, find_peaks\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# --- 1. CORE CALCULATION FUNCTIONS ---\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def compute_acoustic_indices(y, sr):\n",
    "    \"\"\"\n",
    "    Computes six eco-acoustic indices from an audio signal.\n",
    "    \"\"\"\n",
    "    # Create the spectrogram\n",
    "    f, t, Sxx = spectrogram(y, fs=sr, nperseg=1024, noverlap=512)\n",
    "    Sxx += 1e-10  # Add a small epsilon to avoid log(0) or division by zero\n",
    "\n",
    "    # --- ADI (Acoustic Diversity Index) & AEI (Acoustic Evenness Index) ---\n",
    "    S_norm = Sxx / Sxx.sum(axis=0, keepdims=True)\n",
    "    ADI = np.mean(entropy(S_norm, axis=0))\n",
    "    # Avoid division by zero if Sxx has only one frequency bin\n",
    "    AEI = 1.0 - (ADI / np.log(Sxx.shape[0])) if Sxx.shape[0] > 1 else 1.0\n",
    "\n",
    "    # --- ACI (Acoustic Complexity Index) ---\n",
    "    delta = np.abs(np.diff(Sxx, axis=1))\n",
    "    ACI_vals = np.sum(delta, axis=1) / (np.sum(Sxx[:, :-1], axis=1))\n",
    "    ACI_total = np.mean(ACI_vals)\n",
    "\n",
    "    # --- NDSI (Normalized Difference Soundscape Index) ---\n",
    "    bio_band = np.logical_and(f >= 2000, f <= 11000)\n",
    "    anthro_band = np.logical_and(f >= 100, f <= 2000)\n",
    "    B = np.sum(Sxx[bio_band, :])\n",
    "    A = np.sum(Sxx[anthro_band, :])\n",
    "    NDSI = (B - A) / (B + A)\n",
    "\n",
    "    # --- MFC (Mid-Frequency Cover) ---\n",
    "    mid_band = np.logical_and(f >= 2000, f <= 8000)\n",
    "    mid_band_energy = np.sum(Sxx[mid_band, :], axis=0)\n",
    "    total_energy = np.sum(Sxx, axis=0)\n",
    "    threshold = 0.2 * total_energy\n",
    "    MFC = np.mean(mid_band_energy > threshold)\n",
    "\n",
    "    # --- CLS (Cluster Label Count) ---\n",
    "    CLS_list = []\n",
    "    for frame in Sxx.T: # Iterate through each time frame\n",
    "        norm_frame = frame / (np.max(frame))\n",
    "        peaks, _ = find_peaks(norm_frame, height=0.5)\n",
    "        CLS_list.append(len(peaks))\n",
    "    CLS = np.mean(CLS_list)\n",
    "    \n",
    "    return {'ADI': ADI, 'ACI': ACI_total, 'AEI': AEI, 'NDSI': NDSI, 'MFC': MFC, 'CLS': CLS}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T14:15:38.133829Z",
     "iopub.status.busy": "2025-06-19T14:15:38.133490Z",
     "iopub.status.idle": "2025-06-19T14:15:38.141588Z",
     "shell.execute_reply": "2025-06-19T14:15:38.140308Z",
     "shell.execute_reply.started": "2025-06-19T14:15:38.133806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TARGET_SR = 48000\n",
    "SEGMENT_DURATION = 120.0  # 120 seconds\n",
    "SKIP_DURATION = 60    # skip 1 minute after each segment\n",
    "TOTAL_SEGMENTS = 2      # desired number of 2-min samples\n",
    "\n",
    "def segment_audio(audio, fs=TARGET_SR):\n",
    "    \"\"\"\n",
    "    Extracts 10 evenly spaced 1-minute segments from a 30-minute audio clip,\n",
    "    with 2-minute skips between each segment.\n",
    "    \"\"\"\n",
    "    segment_samples = int(SEGMENT_DURATION * fs)\n",
    "    skip_samples = int(SKIP_DURATION * fs)\n",
    "    segments = []\n",
    "\n",
    "    start = 0\n",
    "    for _ in range(TOTAL_SEGMENTS):\n",
    "        end = start + segment_samples\n",
    "        if end > len(audio):\n",
    "            break\n",
    "        segment = audio[start:end]\n",
    "        segments.append(segment)\n",
    "        start += segment_samples + skip_samples  # move start by 3 minutes\n",
    "\n",
    "    return np.array(segments) if segments else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T13:57:30.358709Z",
     "iopub.status.busy": "2025-06-19T13:57:30.358369Z"
    }
   },
   "source": [
    "!ffmpeg -i \"/kaggle/input/noisee/Untitled video - Made with Clipchamp.mp4\" -vn -acodec pcm_s16le -ar 22050 -ac 1 static_noise.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T14:15:42.698823Z",
     "iopub.status.busy": "2025-06-19T14:15:42.698511Z",
     "iopub.status.idle": "2025-06-19T15:00:49.351313Z",
     "shell.execute_reply": "2025-06-19T15:00:49.349038Z",
     "shell.execute_reply.started": "2025-06-19T14:15:42.698803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(DATASET_PATH)):\n",
    "    # Main execution\n",
    "    results = []\n",
    "    filepath = \"\"\n",
    "    # Load static noise clip once\n",
    "    noise_clip, _ = librosa.load(STATIC_NOISE_PATH, sr=TARGET_SR)\n",
    "\n",
    "    for filename in sorted(os.listdir(DATASET_PATH[j])):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            year, month, date, hour, minute = extract_year_month_date_hour_and_minute(filename)\n",
    "            filepath = os.path.join(DATASET_PATH[j], filename)\n",
    "            print(f\"Processing {filename} (Hour: {hour}, Minute: {minute}) ...\")\n",
    "\n",
    "            # Load and denoise audio\n",
    "            audio, sr = librosa.load(filepath, sr=TARGET_SR)\n",
    "            audio_denoised = remove_static_noise(audio, noise_clip)\n",
    "\n",
    "            # Segment into 10x 1-minute samples spaced apart\n",
    "            segments = segment_audio(audio_denoised)\n",
    "\n",
    "            if segments is None:\n",
    "                print(f\"Skipped {filename} (too short)\")\n",
    "                continue\n",
    "\n",
    "            # Process each segment\n",
    "            for i, segment in enumerate(segments):\n",
    "                ADI, ACI, AEI, NDSI, MFC, CLS = compute_acoustic_indices(segment.flatten(), sr)\n",
    "                results.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"Segment\": i + 1,\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Date\": date,\n",
    "                    \"Hour\": hour,\n",
    "                    \"Minute\": minute,\n",
    "                    \"Second\": i * (SEGMENT_DURATION + SKIP_DURATION),  # seconds from start\n",
    "                    \"ADI\": ADI,\n",
    "                    \"ACI\": ACI,\n",
    "                    \"AEI\": AEI,\n",
    "                    \"NDSI\": NDSI,\n",
    "                    \"MFC\": MFC,\n",
    "                    \"CLS\": CLS\n",
    "                })\n",
    "    \n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(OUTPUT_CSV[j], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:00:53.114465Z",
     "iopub.status.busy": "2025-06-19T15:00:53.113563Z",
     "iopub.status.idle": "2025-06-19T15:01:02.001693Z",
     "shell.execute_reply": "2025-06-19T15:01:02.000421Z",
     "shell.execute_reply.started": "2025-06-19T15:00:53.114371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load results into DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by filename and segment number for logical progression\n",
    "results_df.sort_values(by=[\"Filename\", \"Segment\"], inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add an evenly spaced position (X-axis) for plotting\n",
    "results_df[\"X\"] = range(len(results_df))  # 0, 1, 2, ...\n",
    "\n",
    "# Plot each index\n",
    "for idx in [\"ADI\", \"ACI\", \"AEI\", \"NDSI\"]:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(results_df[\"X\"], results_df[idx], marker='o', linestyle='-', alpha=0.8)\n",
    "\n",
    "    # Use Hour as label on the x-axis (even though X is just 0,1,2...)\n",
    "    plt.xticks(results_df[\"X\"][::10], results_df[\"Hour\"][::10], rotation=45)  # show label every 10 segments\n",
    "\n",
    "    plt.title(f\"{idx} Across Segments (Labelled by Hour)\")\n",
    "    plt.xlabel(\"Hour (label only; segments evenly spaced)\")\n",
    "    plt.ylabel(idx)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"lineplot_{idx.lower()}_evenly_spaced_by_hour.png\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7079927,
     "sourceId": 11319209,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7209335,
     "sourceId": 11499765,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "an",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
